{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X, Y = np.loadtxt(\"pizza.txt\", skiprows=1, unpack=True) # load data\n",
    "#r = predict(X, 1.5)\n",
    "#error = predict(X, 1.5) - Y\n",
    "#squared_error = error ** 2\n",
    "#print(squared_error)\n",
    "\n",
    "#prediction\n",
    "def predict(X, w): return (X * w)\n",
    "\n",
    "#loss\n",
    "def loss(X,Y,w): return np.average((predict(X,w)-Y) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, Y, iterations, lr):\n",
    "    w = 0\n",
    "    for i in range(iterations):\n",
    "        current_loss = loss(X, Y, w)\n",
    "        print(\"Iteration %4d => Loss: %.6f\" % (i, current_loss))\n",
    "        if loss(X, Y, w + lr) < current_loss:\n",
    "            w += lr\n",
    "        elif loss(X, Y, w - lr) < current_loss:\n",
    "            w -= lr\n",
    "        else:\n",
    "            return w\n",
    "    raise Exception(\"Couldn't converge within %d iterations\" % iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0 => Loss: 1139.800000\n",
      "Iteration    1 => Loss: 1130.089340\n",
      "Iteration    2 => Loss: 1120.421360\n",
      "Iteration    3 => Loss: 1110.796060\n",
      "Iteration    4 => Loss: 1101.213440\n",
      "Iteration    5 => Loss: 1091.673500\n",
      "Iteration    6 => Loss: 1082.176240\n",
      "Iteration    7 => Loss: 1072.721660\n",
      "Iteration    8 => Loss: 1063.309760\n",
      "Iteration    9 => Loss: 1053.940540\n",
      "Iteration   10 => Loss: 1044.614000\n",
      "Iteration   11 => Loss: 1035.330140\n",
      "Iteration   12 => Loss: 1026.088960\n",
      "Iteration   13 => Loss: 1016.890460\n",
      "Iteration   14 => Loss: 1007.734640\n",
      "Iteration   15 => Loss: 998.621500\n",
      "Iteration   16 => Loss: 989.551040\n",
      "Iteration   17 => Loss: 980.523260\n",
      "Iteration   18 => Loss: 971.538160\n",
      "Iteration   19 => Loss: 962.595740\n",
      "Iteration   20 => Loss: 953.696000\n",
      "Iteration   21 => Loss: 944.838940\n",
      "Iteration   22 => Loss: 936.024560\n",
      "Iteration   23 => Loss: 927.252860\n",
      "Iteration   24 => Loss: 918.523840\n",
      "Iteration   25 => Loss: 909.837500\n",
      "Iteration   26 => Loss: 901.193840\n",
      "Iteration   27 => Loss: 892.592860\n",
      "Iteration   28 => Loss: 884.034560\n",
      "Iteration   29 => Loss: 875.518940\n",
      "Iteration   30 => Loss: 867.046000\n",
      "Iteration   31 => Loss: 858.615740\n",
      "Iteration   32 => Loss: 850.228160\n",
      "Iteration   33 => Loss: 841.883260\n",
      "Iteration   34 => Loss: 833.581040\n",
      "Iteration   35 => Loss: 825.321500\n",
      "Iteration   36 => Loss: 817.104640\n",
      "Iteration   37 => Loss: 808.930460\n",
      "Iteration   38 => Loss: 800.798960\n",
      "Iteration   39 => Loss: 792.710140\n",
      "Iteration   40 => Loss: 784.664000\n",
      "Iteration   41 => Loss: 776.660540\n",
      "Iteration   42 => Loss: 768.699760\n",
      "Iteration   43 => Loss: 760.781660\n",
      "Iteration   44 => Loss: 752.906240\n",
      "Iteration   45 => Loss: 745.073500\n",
      "Iteration   46 => Loss: 737.283440\n",
      "Iteration   47 => Loss: 729.536060\n",
      "Iteration   48 => Loss: 721.831360\n",
      "Iteration   49 => Loss: 714.169340\n",
      "Iteration   50 => Loss: 706.550000\n",
      "Iteration   51 => Loss: 698.973340\n",
      "Iteration   52 => Loss: 691.439360\n",
      "Iteration   53 => Loss: 683.948060\n",
      "Iteration   54 => Loss: 676.499440\n",
      "Iteration   55 => Loss: 669.093500\n",
      "Iteration   56 => Loss: 661.730240\n",
      "Iteration   57 => Loss: 654.409660\n",
      "Iteration   58 => Loss: 647.131760\n",
      "Iteration   59 => Loss: 639.896540\n",
      "Iteration   60 => Loss: 632.704000\n",
      "Iteration   61 => Loss: 625.554140\n",
      "Iteration   62 => Loss: 618.446960\n",
      "Iteration   63 => Loss: 611.382460\n",
      "Iteration   64 => Loss: 604.360640\n",
      "Iteration   65 => Loss: 597.381500\n",
      "Iteration   66 => Loss: 590.445040\n",
      "Iteration   67 => Loss: 583.551260\n",
      "Iteration   68 => Loss: 576.700160\n",
      "Iteration   69 => Loss: 569.891740\n",
      "Iteration   70 => Loss: 563.126000\n",
      "Iteration   71 => Loss: 556.402940\n",
      "Iteration   72 => Loss: 549.722560\n",
      "Iteration   73 => Loss: 543.084860\n",
      "Iteration   74 => Loss: 536.489840\n",
      "Iteration   75 => Loss: 529.937500\n",
      "Iteration   76 => Loss: 523.427840\n",
      "Iteration   77 => Loss: 516.960860\n",
      "Iteration   78 => Loss: 510.536560\n",
      "Iteration   79 => Loss: 504.154940\n",
      "Iteration   80 => Loss: 497.816000\n",
      "Iteration   81 => Loss: 491.519740\n",
      "Iteration   82 => Loss: 485.266160\n",
      "Iteration   83 => Loss: 479.055260\n",
      "Iteration   84 => Loss: 472.887040\n",
      "Iteration   85 => Loss: 466.761500\n",
      "Iteration   86 => Loss: 460.678640\n",
      "Iteration   87 => Loss: 454.638460\n",
      "Iteration   88 => Loss: 448.640960\n",
      "Iteration   89 => Loss: 442.686140\n",
      "Iteration   90 => Loss: 436.774000\n",
      "Iteration   91 => Loss: 430.904540\n",
      "Iteration   92 => Loss: 425.077760\n",
      "Iteration   93 => Loss: 419.293660\n",
      "Iteration   94 => Loss: 413.552240\n",
      "Iteration   95 => Loss: 407.853500\n",
      "Iteration   96 => Loss: 402.197440\n",
      "Iteration   97 => Loss: 396.584060\n",
      "Iteration   98 => Loss: 391.013360\n",
      "Iteration   99 => Loss: 385.485340\n",
      "Iteration  100 => Loss: 380.000000\n",
      "Iteration  101 => Loss: 374.557340\n",
      "Iteration  102 => Loss: 369.157360\n",
      "Iteration  103 => Loss: 363.800060\n",
      "Iteration  104 => Loss: 358.485440\n",
      "Iteration  105 => Loss: 353.213500\n",
      "Iteration  106 => Loss: 347.984240\n",
      "Iteration  107 => Loss: 342.797660\n",
      "Iteration  108 => Loss: 337.653760\n",
      "Iteration  109 => Loss: 332.552540\n",
      "Iteration  110 => Loss: 327.494000\n",
      "Iteration  111 => Loss: 322.478140\n",
      "Iteration  112 => Loss: 317.504960\n",
      "Iteration  113 => Loss: 312.574460\n",
      "Iteration  114 => Loss: 307.686640\n",
      "Iteration  115 => Loss: 302.841500\n",
      "Iteration  116 => Loss: 298.039040\n",
      "Iteration  117 => Loss: 293.279260\n",
      "Iteration  118 => Loss: 288.562160\n",
      "Iteration  119 => Loss: 283.887740\n",
      "Iteration  120 => Loss: 279.256000\n",
      "Iteration  121 => Loss: 274.666940\n",
      "Iteration  122 => Loss: 270.120560\n",
      "Iteration  123 => Loss: 265.616860\n",
      "Iteration  124 => Loss: 261.155840\n",
      "Iteration  125 => Loss: 256.737500\n",
      "Iteration  126 => Loss: 252.361840\n",
      "Iteration  127 => Loss: 248.028860\n",
      "Iteration  128 => Loss: 243.738560\n",
      "Iteration  129 => Loss: 239.490940\n",
      "Iteration  130 => Loss: 235.286000\n",
      "Iteration  131 => Loss: 231.123740\n",
      "Iteration  132 => Loss: 227.004160\n",
      "Iteration  133 => Loss: 222.927260\n",
      "Iteration  134 => Loss: 218.893040\n",
      "Iteration  135 => Loss: 214.901500\n",
      "Iteration  136 => Loss: 210.952640\n",
      "Iteration  137 => Loss: 207.046460\n",
      "Iteration  138 => Loss: 203.182960\n",
      "Iteration  139 => Loss: 199.362140\n",
      "Iteration  140 => Loss: 195.584000\n",
      "Iteration  141 => Loss: 191.848540\n",
      "Iteration  142 => Loss: 188.155760\n",
      "Iteration  143 => Loss: 184.505660\n",
      "Iteration  144 => Loss: 180.898240\n",
      "Iteration  145 => Loss: 177.333500\n",
      "Iteration  146 => Loss: 173.811440\n",
      "Iteration  147 => Loss: 170.332060\n",
      "Iteration  148 => Loss: 166.895360\n",
      "Iteration  149 => Loss: 163.501340\n",
      "Iteration  150 => Loss: 160.150000\n",
      "Iteration  151 => Loss: 156.841340\n",
      "Iteration  152 => Loss: 153.575360\n",
      "Iteration  153 => Loss: 150.352060\n",
      "Iteration  154 => Loss: 147.171440\n",
      "Iteration  155 => Loss: 144.033500\n",
      "Iteration  156 => Loss: 140.938240\n",
      "Iteration  157 => Loss: 137.885660\n",
      "Iteration  158 => Loss: 134.875760\n",
      "Iteration  159 => Loss: 131.908540\n",
      "Iteration  160 => Loss: 128.984000\n",
      "Iteration  161 => Loss: 126.102140\n",
      "Iteration  162 => Loss: 123.262960\n",
      "Iteration  163 => Loss: 120.466460\n",
      "Iteration  164 => Loss: 117.712640\n",
      "Iteration  165 => Loss: 115.001500\n",
      "Iteration  166 => Loss: 112.333040\n",
      "Iteration  167 => Loss: 109.707260\n",
      "Iteration  168 => Loss: 107.124160\n",
      "Iteration  169 => Loss: 104.583740\n",
      "Iteration  170 => Loss: 102.086000\n",
      "Iteration  171 => Loss: 99.630940\n",
      "Iteration  172 => Loss: 97.218560\n",
      "Iteration  173 => Loss: 94.848860\n",
      "Iteration  174 => Loss: 92.521840\n",
      "Iteration  175 => Loss: 90.237500\n",
      "Iteration  176 => Loss: 87.995840\n",
      "Iteration  177 => Loss: 85.796860\n",
      "Iteration  178 => Loss: 83.640560\n",
      "Iteration  179 => Loss: 81.526940\n",
      "Iteration  180 => Loss: 79.456000\n",
      "Iteration  181 => Loss: 77.427740\n",
      "Iteration  182 => Loss: 75.442160\n",
      "Iteration  183 => Loss: 73.499260\n",
      "Iteration  184 => Loss: 71.599040\n",
      "Iteration  185 => Loss: 69.741500\n",
      "Iteration  186 => Loss: 67.926640\n",
      "Iteration  187 => Loss: 66.154460\n",
      "Iteration  188 => Loss: 64.424960\n",
      "Iteration  189 => Loss: 62.738140\n",
      "Iteration  190 => Loss: 61.094000\n",
      "Iteration  191 => Loss: 59.492540\n",
      "Iteration  192 => Loss: 57.933760\n",
      "Iteration  193 => Loss: 56.417660\n",
      "Iteration  194 => Loss: 54.944240\n",
      "Iteration  195 => Loss: 53.513500\n",
      "Iteration  196 => Loss: 52.125440\n",
      "Iteration  197 => Loss: 50.780060\n",
      "Iteration  198 => Loss: 49.477360\n",
      "Iteration  199 => Loss: 48.217340\n",
      "Iteration  200 => Loss: 47.000000\n",
      "Iteration  201 => Loss: 45.825340\n",
      "Iteration  202 => Loss: 44.693360\n",
      "Iteration  203 => Loss: 43.604060\n",
      "Iteration  204 => Loss: 42.557440\n",
      "Iteration  205 => Loss: 41.553500\n",
      "Iteration  206 => Loss: 40.592240\n",
      "Iteration  207 => Loss: 39.673660\n",
      "Iteration  208 => Loss: 38.797760\n",
      "Iteration  209 => Loss: 37.964540\n",
      "Iteration  210 => Loss: 37.174000\n",
      "Iteration  211 => Loss: 36.426140\n",
      "Iteration  212 => Loss: 35.720960\n",
      "Iteration  213 => Loss: 35.058460\n",
      "Iteration  214 => Loss: 34.438640\n",
      "Iteration  215 => Loss: 33.861500\n",
      "Iteration  216 => Loss: 33.327040\n",
      "Iteration  217 => Loss: 32.835260\n",
      "Iteration  218 => Loss: 32.386160\n",
      "Iteration  219 => Loss: 31.979740\n",
      "Iteration  220 => Loss: 31.616000\n",
      "Iteration  221 => Loss: 31.294940\n",
      "Iteration  222 => Loss: 31.016560\n",
      "Iteration  223 => Loss: 30.780860\n",
      "Iteration  224 => Loss: 30.587840\n",
      "Iteration  225 => Loss: 30.437500\n",
      "Iteration  226 => Loss: 30.329840\n",
      "Iteration  227 => Loss: 30.264860\n",
      "Iteration  228 => Loss: 30.242560\n",
      "\n",
      "w=2.280\n",
      "Prediction: x=100 => y=228.00\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Import data\n",
    "    X, Y = np.loadtxt(\"pizza.txt\", skiprows=1, unpack=True)\n",
    "    # Train system\n",
    "    w = train(X, Y, iterations=10000, lr=0.01)\n",
    "    print(\"\\nw=%.3f\" % w)\n",
    "    print(\"Prediction: x=%d => y=%.2f\" % (100, predict(100, w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
